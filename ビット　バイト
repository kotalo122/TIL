コンピュータが表現する最小の単位がビット（bit)
８ビットをひとまとめにしたバイト(Byte)を主に使う。

「500b」で末尾にbが書いてある場合はビット
「500B」と末尾に大文字のBが書いてある場合はバイト

1バイトであらわせる数の範囲
1ビットは
1 or 0


2ビットは
00
01
10
11
４通りに増える

2ビットだと2進数2桁になるので、2²個の数を表現できる
3ビットだと2³個で8通り。4ビットだと2⁴個で16通り
8ビットだと256通り

負の数を入れると表現できる数値は正と負に２等分される
符号ありの場合はあらわせる数
00000000 ⇨ 00000001 ~ 0111111
             1         127

00000000 ⇨ 11111111 ~ 10000001 ~ 10000000
             -1        -127       -128

様々な補助単位
m(メートル）という長さの単位、40,000mだったときに40km
この時の「k」を補助単位と呼ぶ

バイトも補助単位を使う
下記がその補助単位の一覧

記憶容量など大きい数値を表す補助単位
補助単位	意味	説明
キロ(k)	10³	基本単位 * 1,000倍
メガ(M)	10⁶	基本単位 * 1,000,000倍
ギガ(G)	10⁹	基本単位 * 1,000,000,000倍
テラ(T)	10¹²	基本単位 * 1,000,000,000,000倍
処理速度など小さい数値を表す補助単位
補助単位	意味	説明
ミリ(m)	10⁻³	基本単位 / 1,000倍
マイクロ(μ)	10⁻⁶	基本単位 / 1,000,000倍
ナノ(n)	10⁻⁹	基本単位 / 1,000,000,000倍
ピコ(p)	10⁻¹²	基本単位 / 1,000,000,000,000倍
